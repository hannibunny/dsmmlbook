

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Machine Learning in a few lines of Code &#8212; Machine Learning (DSM)</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-dropdown.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script type="text/javascript" src="../_static/togglebutton.js"></script>
    <script type="text/javascript" src="../_static/clipboard.min.js"></script>
    <script type="text/javascript" src="../_static/copybutton.js"></script>
    <script type="text/javascript" src="../_static/sphinx-book-theme.js"></script>
    <script type="text/javascript">var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" type="text/javascript" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script type="text/javascript">
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" type="text/javascript" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Basic Concepts of Data Mining and Machine Learning" href="00BasicConcepts.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/hdmlogomed.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Machine Learning (DSM)</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Overview.html">
   Machine Learning with Python
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Lecture
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="00BasicConcepts.html">
   Basic Concepts of Data Mining and Machine Learning
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Machine Learning in a few lines of Code
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Lecture/00MachineLearningInaNutshell.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/Lecture/00MachineLearningInaNutshell.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/executablebooks/jupyter-book/blob/master/Lecture/00MachineLearningInaNutshell.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#goal">
   Goal
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#python-packages-for-data-mining-and-machine-learning">
   Python Packages for Data Mining and Machine Learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scikit-learn">
     Scikit-Learn
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#crisp-process-in-a-few-lines-of-code">
   Crisp Process in a few lines of code
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#business-understanding">
     Business Understanding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#access-data-from-csv-file">
     Access Data from .csv file
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#understand-data">
     Understand Data
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#numeric-features">
       Numeric features:
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#categorical-features">
       Categorical Features:
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#some-visualization">
       Some visualization:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preprocess-data">
     Preprocess Data
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transformation-of-non-numeric-features">
       Transformation of non-numeric Features
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#one-hot-encoding-of-nominal-features">
       One-Hot-Encoding of nominal Features
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#scaling-of-data">
       Scaling of data
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelling">
     Modelling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluation">
     Evaluation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualisation">
     Visualisation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix">
   Appendix
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelling-of-words-and-documents">
     Modelling of words and documents
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#one-hot-encoding-of-single-words">
       One-Hot-Encoding of Single Words
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#word-embeddings">
       Word Embeddings
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bag-of-word-modell-of-documents">
       Bag of Word Modell of documents
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="machine-learning-in-a-few-lines-of-code">
<h1>Machine Learning in a few lines of Code<a class="headerlink" href="#machine-learning-in-a-few-lines-of-code" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Author: Johannes Maucher</p></li>
<li><p>Last Update: 26.11.2020</p></li>
</ul>
<div class="section" id="goal">
<h2>Goal<a class="headerlink" href="#goal" title="Permalink to this headline">¶</a></h2>
<p>This notebook shall demonstrate the implementation of a complete Data Mining Process from data access to model evaluation and interpretation.</p>
<img alt="https://maucher.home.hdm-stuttgart.de/Pics/crispIndall.png" class="align-center" src="https://maucher.home.hdm-stuttgart.de/Pics/crispIndall.png" />
<p>The steps of the <em>Cross Industry Standard Process for Datamining (CRISP)</em> are depicted above. Each of these steps can be quite complex. In the current notebook however, a simple example is used to provide you a glimpse of</p>
<ul class="simple">
<li><p>each of the crisp phases</p></li>
<li><p>the basics of Python packages used in the crisp process.</p></li>
</ul>
</div>
<div class="section" id="python-packages-for-data-mining-and-machine-learning">
<h2>Python Packages for Data Mining and Machine Learning<a class="headerlink" href="#python-packages-for-data-mining-and-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>For implementing the entire Data Mining process chain in Python the following Python packages are commonly used:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.numpy.org">numpy</a> and <a class="reference external" href="https://www.scipy.org">scipy</a> for efficient datastructures and scientific calculations</p></li>
<li><p><a class="reference external" href="https://pandas.pydata.org">pandas</a> for typical data science tasks, such as data access, descriptive statistics, joining of datasets, correlation analysis, etc.</p></li>
<li><p><a class="reference external" href="https://matplotlib.org">matplotlib</a>, <a class="reference external" href="https://seaborn.pydata.org/">seaborn</a> and <a class="reference external" href="https://bokeh.pydata.org/en/latest/">Bokeh</a> for visualisation</p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a> for conventional Machine Learning, i.e. all but Deep Neural Networks</p></li>
<li><p><a class="reference external" href="https://www.tensorflow.org">tensorflow</a> and <a class="reference external" href="https://keras.io">keras</a> for Deep Neural Networks</p></li>
</ul>
<div class="section" id="scikit-learn">
<h3>Scikit-Learn<a class="headerlink" href="#scikit-learn" title="Permalink to this headline">¶</a></h3>
<p>For conventional Machine Learning scikit-learn provides a comprehensive bunch of algorithms and functions. The basic concepts of scikit-learn are:</p>
<ul class="simple">
<li><p>it is primarily built on Numpy. In particular internal and external data structures are <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html">Numpy Arrays</a>.</p></li>
<li><p>All algorithms, which somehow transform data belong to the <strong>Transformer</strong>-class, e.g. <em>PCA, Normalizer, StandardScaler, OneHotEncoder</em>, etc. These transformers are trained by applying the <code class="docutils literal notranslate"><span class="pre">.fit(traindata)</span></code>-method. Once they are trained, there <code class="docutils literal notranslate"><span class="pre">.transform(data)</span></code>-method can be called in order to transform <em>data</em>. If the data, used for training the transformer, shall be transformed immediately after training, the <code class="docutils literal notranslate"><span class="pre">.fit_transform(data)</span></code>-method can be applied.</p></li>
<li><p>All Machine Learning algorithms for supervised and unsupervised learning belong to the <strong>Estimator</strong> class, e.g. <em>LogisticRegression, SVM, MLP, Kmeans</em>, etc. These estimators are trained by applying the
<code class="docutils literal notranslate"><span class="pre">.fit(trainfeatures)</span></code>- or <code class="docutils literal notranslate"><span class="pre">.fit(trainfeatures,trainlabels)</span></code>-method. The former configuration is applied for unsupervised-, the latter for supervised learning. Once an estimator is trained, it can be applied for clustering, classification or regression by envoking the <code class="docutils literal notranslate"><span class="pre">.predict(data)</span></code>-method.</p></li>
<li><p>At their interfaces all <strong>Transformers</strong> and <strong>Estimators</strong> apply <em>Numpy Arrays</em>.</p></li>
</ul>
</div>
</div>
<div class="section" id="crisp-process-in-a-few-lines-of-code">
<h2>Crisp Process in a few lines of code<a class="headerlink" href="#crisp-process-in-a-few-lines-of-code" title="Permalink to this headline">¶</a></h2>
<div class="section" id="business-understanding">
<h3>Business Understanding<a class="headerlink" href="#business-understanding" title="Permalink to this headline">¶</a></h3>
<p>In this example, structured data is available from a .csv file. Data has been collected by a U.S. insurance company. For 1339 clients the following features are contained:</p>
<ul class="simple">
<li><p>age</p></li>
<li><p>sex</p></li>
<li><p>smoker</p></li>
<li><p>Body-Mass-Index (BMI)</p></li>
<li><p>Number of children</p></li>
<li><p>living region</p></li>
<li><p>annual charges</p></li>
</ul>
<p style="color:red">The goal is to learn a model, which predicts annual charges of clients from the other 5 features.</p><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;whitegrid&#39;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;muted&#39;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">filterwarnings</span>
<span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="access-data-from-csv-file">
<h3>Access Data from .csv file<a class="headerlink" href="#access-data-from-csv-file" title="Permalink to this headline">¶</a></h3>
<p>For accessing data <a class="reference external" href="https://pandas.pydata.org/docs/reference/io.html">pandas provides comfortable interfaces</a> to a wide range of different data formats, such as csv, Excel, Json, SQL, HDF5 and many others.</p>
<p>Data of this example is available in a csv-file, which can be accessed as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">=</span><span class="s2">&quot;../Data/insurance.csv&quot;</span>
<span class="n">insurancedf</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">na_values</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot; &quot;</span><span class="p">,</span><span class="s2">&quot;null&quot;</span><span class="p">])</span>
<span class="n">insurancedf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>bmi</th>
      <th>children</th>
      <th>smoker</th>
      <th>region</th>
      <th>charges</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>19</td>
      <td>female</td>
      <td>27.900</td>
      <td>0</td>
      <td>yes</td>
      <td>southwest</td>
      <td>16884.92400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>18</td>
      <td>male</td>
      <td>33.770</td>
      <td>1</td>
      <td>no</td>
      <td>southeast</td>
      <td>1725.55230</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28</td>
      <td>male</td>
      <td>33.000</td>
      <td>3</td>
      <td>no</td>
      <td>southeast</td>
      <td>4449.46200</td>
    </tr>
    <tr>
      <th>3</th>
      <td>33</td>
      <td>male</td>
      <td>22.705</td>
      <td>0</td>
      <td>no</td>
      <td>northwest</td>
      <td>21984.47061</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>male</td>
      <td>28.880</td>
      <td>0</td>
      <td>no</td>
      <td>northwest</td>
      <td>3866.85520</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="understand-data">
<h3>Understand Data<a class="headerlink" href="#understand-data" title="Permalink to this headline">¶</a></h3>
<p>At the very beginning of each datamining task one should try to understand the given data. This task comprises:</p>
<ul class="simple">
<li><p>determine how <em>clean</em> the data is: Are there missing values, type-errors, value-errors (outliers), etc.</p></li>
<li><p>determine descriptive statistics</p></li>
<li><p>investigate correlations</p></li>
</ul>
<p><em>Data visualistion</em> can help to clarify these questions.</p>
<p><strong>Determine Type of Data:</strong></p>
<p>In this example features <em>sex</em>, <em>smoker</em> and <em>region</em> are nominal. All other features are numerical.</p>
<div class="section" id="numeric-features">
<h4>Numeric features:<a class="headerlink" href="#numeric-features" title="Permalink to this headline">¶</a></h4>
<p>For numeric variables standard descriptive statistics such as mean, standard-deviation, quantiles etc. are calculated:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">insurancedf</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>bmi</th>
      <th>children</th>
      <th>charges</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1338.000000</td>
      <td>1338.000000</td>
      <td>1338.000000</td>
      <td>1338.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>39.207025</td>
      <td>30.663397</td>
      <td>1.094918</td>
      <td>13270.422265</td>
    </tr>
    <tr>
      <th>std</th>
      <td>14.049960</td>
      <td>6.098187</td>
      <td>1.205493</td>
      <td>12110.011237</td>
    </tr>
    <tr>
      <th>min</th>
      <td>18.000000</td>
      <td>15.960000</td>
      <td>0.000000</td>
      <td>1121.873900</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>27.000000</td>
      <td>26.296250</td>
      <td>0.000000</td>
      <td>4740.287150</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>39.000000</td>
      <td>30.400000</td>
      <td>1.000000</td>
      <td>9382.033000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>51.000000</td>
      <td>34.693750</td>
      <td>2.000000</td>
      <td>16639.912515</td>
    </tr>
    <tr>
      <th>max</th>
      <td>64.000000</td>
      <td>53.130000</td>
      <td>5.000000</td>
      <td>63770.428010</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="categorical-features">
<h4>Categorical Features:<a class="headerlink" href="#categorical-features" title="Permalink to this headline">¶</a></h4>
<p>For non-numeric features the possible values and their count can be calculated as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">catFeats</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">,</span><span class="s1">&#39;smoker&#39;</span><span class="p">,</span><span class="s1">&#39;region&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">cf</span> <span class="ow">in</span> <span class="n">catFeats</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Feature </span><span class="si">%s</span><span class="s2"> :&quot;</span><span class="o">%</span><span class="k">cf</span>)
    <span class="nb">print</span><span class="p">(</span><span class="n">insurancedf</span><span class="p">[</span><span class="n">cf</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature sex :
male      676
female    662
Name: sex, dtype: int64

Feature smoker :
no     1064
yes     274
Name: smoker, dtype: int64

Feature region :
southeast    364
northwest    325
southwest    325
northeast    324
Name: region, dtype: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="some-visualization">
<h4>Some visualization:<a class="headerlink" href="#some-visualization" title="Permalink to this headline">¶</a></h4>
<p>The standard Python visualization library is <a class="reference external" href="https://matplotlib.org">matplotlib</a>. Many other packages integrate and/or extend matplotlib’s capabilities. For example <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html">pandas integrates matplotlib’s plot() function</a>, such that this function can be invoked on dataframe-objects.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span><span class="o">=</span><span class="n">insurancedf</span><span class="p">[</span><span class="s2">&quot;charges&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;annual charges per customer&quot;</span><span class="p">,</span>
                            <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;None&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Cliend ID&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Annual Charges (USD)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Annual Charges (USD)&#39;)
</pre></div>
</div>
<img alt="../_images/00MachineLearningInaNutshell_18_1.png" src="../_images/00MachineLearningInaNutshell_18_1.png" />
</div>
</div>
<p>Analysing the distribution of single attributes helps to understand data. For example it helps to detect outliers. Outliers should be removed from the data, since they may yield disturbed models. Moreover, knowing the univariate distribution may help us in determining necessary preprocessing steps, such as standardization. For classification tasks, the distribution of the class-labels within the training set is a critical point. In the case of extremely unbalanced label-distributions under- or oversampling can be applied for balancing.</p>
<p>Univariate distributions can be visualized by e.g. histograms, boxplots or violinplots as demonstrated below in the code-cells below:</p>
<p>Among other <a class="reference external" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html">plot-kinds</a> boxplots can be generated for dataframe-columns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">insurancedf</span><span class="p">[</span><span class="s2">&quot;charges&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;box&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fef36b7e450&gt;
</pre></div>
</div>
<img alt="../_images/00MachineLearningInaNutshell_20_1.png" src="../_images/00MachineLearningInaNutshell_20_1.png" />
</div>
</div>
<p>Above, the <em>Pandas</em> <code class="docutils literal notranslate"><span class="pre">plot()</span></code>-function, which applies <em>Matplotlib</em> <code class="docutils literal notranslate"><span class="pre">plot()</span></code>-function is applied for generating the Box-plot. <em>Seaborn</em> is another visualisation lib for Python, which is particularly dedicated for statistical visualisations. E.g. it provides more functions to visualize data-distributions and -correlations. Below, a seaborn-<em>violinplot</em> is generated:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">insurancedf</span><span class="p">[</span><span class="s2">&quot;charges&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/00MachineLearningInaNutshell_22_0.png" src="../_images/00MachineLearningInaNutshell_22_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="preprocess-data">
<h3>Preprocess Data<a class="headerlink" href="#preprocess-data" title="Permalink to this headline">¶</a></h3>
<div class="section" id="transformation-of-non-numeric-features">
<h4>Transformation of non-numeric Features<a class="headerlink" href="#transformation-of-non-numeric-features" title="Permalink to this headline">¶</a></h4>
<p>Non-numeric features must be transformed to a numeric representation. For this we apply the <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> from scikit-learn, which belongs to the class of <em>Transformers</em>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="k">for</span> <span class="n">cf</span> <span class="ow">in</span> <span class="n">catFeats</span><span class="p">:</span>
    <span class="n">insurancedf</span><span class="p">[</span><span class="n">cf</span><span class="p">]</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">insurancedf</span><span class="p">[</span><span class="n">cf</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">insurancedf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>bmi</th>
      <th>children</th>
      <th>smoker</th>
      <th>region</th>
      <th>charges</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>19</td>
      <td>0</td>
      <td>27.900</td>
      <td>0</td>
      <td>1</td>
      <td>3</td>
      <td>16884.92400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>18</td>
      <td>1</td>
      <td>33.770</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>1725.55230</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28</td>
      <td>1</td>
      <td>33.000</td>
      <td>3</td>
      <td>0</td>
      <td>2</td>
      <td>4449.46200</td>
    </tr>
    <tr>
      <th>3</th>
      <td>33</td>
      <td>1</td>
      <td>22.705</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>21984.47061</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>1</td>
      <td>28.880</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>3866.85520</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="one-hot-encoding-of-nominal-features">
<h4>One-Hot-Encoding of nominal Features<a class="headerlink" href="#one-hot-encoding-of-nominal-features" title="Permalink to this headline">¶</a></h4>
<p>For <strong>non-binary nominal features</strong> a transformation into a numeric value is not sufficient, because algorithms interpret integers as ordinal data. Therefore non-binary nominal features must be <strong>One-Hot-Encoded</strong>. For columns of pandas dataframes the <code class="docutils literal notranslate"><span class="pre">get_dummies()</span></code>-function does the job. In the code-cell below the columns are reordered after One-Hot-Encoding, such that the attribute, which shall be predicted (charges) remains the last column:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">insurancedfOH</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">insurancedf</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;region&quot;</span><span class="p">])</span>
<span class="n">insurancedfOH</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">ch</span><span class="o">=</span><span class="n">insurancedfOH</span><span class="p">[</span><span class="s2">&quot;charges&quot;</span><span class="p">]</span>
<span class="n">insurancedfOH</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;charges&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">insurancedfOH</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">insurancedfOH</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="s1">&#39;charges&#39;</span><span class="p">,</span> <span class="n">ch</span><span class="p">)</span>
<span class="n">insurancedfOH</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>bmi</th>
      <th>children</th>
      <th>smoker</th>
      <th>region_0</th>
      <th>region_1</th>
      <th>region_2</th>
      <th>region_3</th>
      <th>charges</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>19</td>
      <td>0</td>
      <td>27.900</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>16884.92400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>18</td>
      <td>1</td>
      <td>33.770</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1725.55230</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28</td>
      <td>1</td>
      <td>33.000</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>4449.46200</td>
    </tr>
    <tr>
      <th>3</th>
      <td>33</td>
      <td>1</td>
      <td>22.705</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>21984.47061</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32</td>
      <td>1</td>
      <td>28.880</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>3866.85520</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Theory says that nominal features must be One-Hot-encoded. However, in practice prediction-accuracy may be better if One-Hot-encoding is not applied. In order to find out, which option is better, both variants must be implemented and evaluated. Below, the non-One-Hot-Encoded dataset <code class="docutils literal notranslate"><span class="pre">insurancedf</span></code> is applied for modelling. Apply also the One-Hot-encoded dataset <code class="docutils literal notranslate"><span class="pre">insurancedfOH</span></code> and determine, which variant performs better.</p>
</div>
</div>
<div class="section" id="scaling-of-data">
<h4>Scaling of data<a class="headerlink" href="#scaling-of-data" title="Permalink to this headline">¶</a></h4>
<p>Except decision trees and ensemble methods, which contain decision trees, nearly all machine learning algorithms require features of similar scale at the input. Since the value ranges of practical data can be very different a corresponding scaling must be performed in the preprocessing chain. The most common scaling approaches are <em>normalization (MinMax-scaling)</em> and <em>standardization</em>.</p>
<p><strong>Normalization:</strong> In order to normalize feature <em>x</em> it’s minimum <span class="math notranslate nohighlight">\(x_{min}\)</span> and maximum <span class="math notranslate nohighlight">\(x_{max}\)</span> must be determined. Then the normalized values <span class="math notranslate nohighlight">\(x_n^{(i)}\)</span> are calculated from the original values <span class="math notranslate nohighlight">\(x^{(i)}\)</span> by</p>
<div class="math notranslate nohighlight">
\[
x_n^{(i)}=\frac{x^{(i)}-x_{min}}{x_{max}-x_{min}}.
\]</div>
<p>The range of normalized values is <span class="math notranslate nohighlight">\([0,1]\)</span>. A problem of this type of scaling is that in the case of outliers the value range of non-outliers may be very small.</p>
<p><strong>Standardization:</strong> In order to standardize feature <em>x</em> it’s mean value <span class="math notranslate nohighlight">\(\mu_x\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma_x\)</span> must be determined. Then the standardized values <span class="math notranslate nohighlight">\(x_s^{(i)}\)</span> are calculated from the original values <span class="math notranslate nohighlight">\(x^{(i)}\)</span> by</p>
<div class="math notranslate nohighlight">
\[
x_s^{(i)}=\frac{x^{(i)}-\mu_x}{\sigma_x}
\]</div>
<p>All standardized features have zero mean and a standard deviation of one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">StandardScaler</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">normalizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">insurancedf</span><span class="p">)</span>
<span class="n">insurancedfNormed</span> <span class="o">=</span> <span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">insurancedf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Min-Max Normalized Data:&quot;</span><span class="p">)</span>
<span class="n">insurancedfNormed</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Min-Max Normalized Data:
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.022, 0.   , 0.321, ..., 1.   , 1.   , 0.252],
       [0.   , 1.   , 0.479, ..., 0.   , 0.667, 0.01 ],
       [0.217, 1.   , 0.458, ..., 0.   , 0.667, 0.053],
       ...,
       [0.   , 0.   , 0.562, ..., 0.   , 0.667, 0.008],
       [0.065, 0.   , 0.265, ..., 0.   , 1.   , 0.014],
       [0.935, 0.   , 0.353, ..., 1.   , 0.333, 0.447]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">standardizer</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">standardizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">insurancedf</span><span class="p">)</span>
<span class="n">insurancedfStandardized</span> <span class="o">=</span> <span class="n">standardizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">insurancedf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Standardized Data:&quot;</span><span class="p">)</span>
<span class="n">insurancedfStandardized</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Standardized Data:
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-1.439, -1.011, -0.453, ...,  1.971,  1.344,  0.299],
       [-1.51 ,  0.99 ,  0.51 , ..., -0.507,  0.438, -0.954],
       [-0.798,  0.99 ,  0.383, ..., -0.507,  0.438, -0.729],
       ...,
       [-1.51 , -1.011,  1.015, ..., -0.507,  0.438, -0.962],
       [-1.296, -1.011, -0.798, ..., -0.507,  1.344, -0.93 ],
       [ 1.552, -1.011, -0.261, ...,  1.971, -0.467,  1.311]])
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As can be seen above, both transformers must be fitted to data by applying the <code class="docutils literal notranslate"><span class="pre">fit()</span></code>-method. Within this method the parameters for the transformation must be learned. These are the columnwise <code class="docutils literal notranslate"><span class="pre">min</span></code> and <code class="docutils literal notranslate"><span class="pre">max</span></code> in the case of the <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> and the columnwise <code class="docutils literal notranslate"><span class="pre">mean</span></code> and <code class="docutils literal notranslate"><span class="pre">standard-deviation</span></code> in the case of the <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>. Once these transformers are fitted (i.e. the parameters are learned), the <code class="docutils literal notranslate"><span class="pre">transform()</span></code>-method can be invoked for actually transforming the data. It is important, that in the context of Machine Learning, the <code class="docutils literal notranslate"><span class="pre">fit()</span></code>-method is only invoked for the training data. Then the fitted transformer is applied to transform <strong>training- and test-data</strong>. It is not valid to learn individual parameters for test-data, since in Machine Learning we pretend test-data to be unknown in advance.</p>
</div>
</div>
</div>
<div class="section" id="modelling">
<h3>Modelling<a class="headerlink" href="#modelling" title="Permalink to this headline">¶</a></h3>
<p>In this example a regression-model shall be learned, which can be applied to estimate the annual charges, given the other 6 features of a person. Since we also like to evaluate the learned model, we have to split the set of all labeled data into 2 disjoint sets - one for training and the other for test.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Since the goal of this section is to keep things as simple as possible, we neglect One-Hot-Encoding and Scaling here. In an offline experiment it has been shown, that for this data and the applied ML-algorithm, the two transformations yield no significant performance difference.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<p>Split input-features from output-label:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">=</span><span class="n">insurancedf</span><span class="o">.</span><span class="n">values</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># all features, which shall be applied as input for the prediction</span>
<span class="n">y</span><span class="o">=</span><span class="n">insurancedf</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># annual charges, i.e. the output-label that shall be predicted</span>
</pre></div>
</div>
</div>
</div>
<p>Note that in the code cell above, the <code class="docutils literal notranslate"><span class="pre">values</span></code>-attribute of pandas dataframes has been invoked. This attribute contains only the data-part of a pandas-dataframe. The format of this data-part is a numpy-array. I.e. the variables <code class="docutils literal notranslate"><span class="pre">X</span></code>and <code class="docutils literal notranslate"><span class="pre">y</span></code> are numpy-arrays:</p>
<p>Split training- and test-partition:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>First 5 rows of the training-partition:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">,:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[52.   ,  1.   , 30.2  ,  1.   ,  0.   ,  3.   ],
       [47.   ,  0.   , 29.37 ,  1.   ,  0.   ,  2.   ],
       [48.   ,  1.   , 40.565,  2.   ,  1.   ,  1.   ],
       [61.   ,  1.   , 38.38 ,  0.   ,  0.   ,  1.   ],
       [51.   ,  0.   , 18.05 ,  0.   ,  0.   ,  1.   ]])
</pre></div>
</div>
</div>
</div>
<p>In scikit-learn a model is learned by calling the <code class="docutils literal notranslate"><span class="pre">fit(X,y)</span></code>-method of the corresponding algorithm-class. The arguments <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are the array of input-samples and corresponding output-labels, respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="n">linreg</span><span class="o">=</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">linreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
</pre></div>
</div>
</div>
</div>
<p>In the same way as <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> has been applied in the code cell above, any regression algorithm, provided by <a class="reference external" href="https://scikit-learn.org/stable/supervised_learning.html#supervised-learning">scikit-learn</a> can be imported and applied. Even conventional feed forward neural networks such as the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor">Multi Layer Perceptron (MLP) for Regression</a> are provided.</p>
</div>
<div class="section" id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">¶</a></h3>
<p>Once the model has been learned it can be applied for predictions. Here the model output for the test-data is calculated:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ypred</span><span class="o">=</span><span class="n">linreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next, for the first 10 persons of the test-partition the prediction of the model and the true charges are printed:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ypred</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span><span class="n">y_test</span><span class="p">[:</span><span class="mi">10</span><span class="p">]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted Charges: </span><span class="si">{0:2.2f}</span><span class="s2"> </span><span class="se">\t</span><span class="s2"> True Charges: </span><span class="si">{1:2.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span><span class="n">target</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted Charges: 11051.55 	 True Charges: 9724.53
Predicted Charges: 9821.28 	 True Charges: 8547.69
Predicted Charges: 37867.57 	 True Charges: 45702.02
Predicted Charges: 16125.71 	 True Charges: 12950.07
Predicted Charges: 6920.27 	 True Charges: 9644.25
Predicted Charges: 3879.39 	 True Charges: 4500.34
Predicted Charges: 1448.92 	 True Charges: 2198.19
Predicted Charges: 14390.18 	 True Charges: 11436.74
Predicted Charges: 9022.95 	 True Charges: 7537.16
Predicted Charges: 7458.83 	 True Charges: 5425.02
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html">scikit-learn provides a bunch of metrics</a> for evaluation classification-, regression- and clustering models. For this task we apply the <code class="docutils literal notranslate"><span class="pre">mean_absolute_error</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mae</span><span class="o">=</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">ypred</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mae</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4013.6929857812065
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="visualisation">
<h3>Visualisation<a class="headerlink" href="#visualisation" title="Permalink to this headline">¶</a></h3>
<p>For all test-datasets the true-charges are plotted versus the predicted charges. The blue line indicates <code class="docutils literal notranslate"><span class="pre">predicted=true</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ypred</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="s2">&quot;ro&quot;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_test</span><span class="p">)],[</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_test</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Charges&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Charges&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Estimated vs. True Charges&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/00MachineLearningInaNutshell_56_0.png" src="../_images/00MachineLearningInaNutshell_56_0.png" />
</div>
</div>
<p>Finally, we split smokers from non-smokers and analyse the model’s prediction for both partitions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_test_smoker</span><span class="o">=</span><span class="n">y_test</span><span class="p">[</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_pred_smoker</span><span class="o">=</span><span class="n">ypred</span><span class="p">[</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_test_nonsmoker</span><span class="o">=</span><span class="n">y_test</span><span class="p">[</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y_pred_nonsmoker</span><span class="o">=</span><span class="n">ypred</span><span class="p">[</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_pred_smoker</span><span class="p">,</span><span class="n">y_test_smoker</span><span class="p">,</span><span class="s2">&quot;ro&quot;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;smoker&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_pred_nonsmoker</span><span class="p">,</span><span class="n">y_test_nonsmoker</span><span class="p">,</span><span class="s2">&quot;go&quot;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;non smoker&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_test</span><span class="p">)],[</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_test</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Charges&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Charges&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Estimated vs. True Charges&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/00MachineLearningInaNutshell_60_0.png" src="../_images/00MachineLearningInaNutshell_60_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="appendix">
<h2>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">¶</a></h2>
<div class="section" id="modelling-of-words-and-documents">
<h3>Modelling of words and documents<a class="headerlink" href="#modelling-of-words-and-documents" title="Permalink to this headline">¶</a></h3>
<p>In the example above different types of data, numeric and categorial, have been applied. It has been shown how categorical data is mapped to numeric values or numeric vectors, such that it can be applied as input of a Machine Learning algorithm.</p>
<p>Another type of data is text, either single words, sentences, sections or entire documents. How to map these types to numeric representations?</p>
<div class="section" id="one-hot-encoding-of-single-words">
<h4>One-Hot-Encoding of Single Words<a class="headerlink" href="#one-hot-encoding-of-single-words" title="Permalink to this headline">¶</a></h4>
<p>A very simple option for representing single words as numeric vectors, is One-Hot-Encoding. This type of encoding has already been introduced above for modelling non-binary categorial features. Each possible value (word) is uniquely mapped to an index, and the associated vector contains only zeros, except at the position of the value’s (word’s) index.</p>
<p>For example, assume that the entire set of possible words is</p>
<div class="math notranslate nohighlight">
\[
V=(\mbox{all, and, at, boys, girls, home, kids, not, stay}).
\]</div>
<p>Then a possible One-Hot-Encoding of these words is then</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>all</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>and</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>at</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>boys</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>girls</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>home</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>kids</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>not</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>stay</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simpleWordDF</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="s2">&quot;and&quot;</span><span class="p">,</span> <span class="s2">&quot;at&quot;</span><span class="p">,</span> <span class="s2">&quot;boys&quot;</span><span class="p">,</span> <span class="s2">&quot;girls&quot;</span><span class="p">,</span> <span class="s2">&quot;home&quot;</span><span class="p">,</span> <span class="s2">&quot;kids&quot;</span><span class="p">,</span> <span class="s2">&quot;not&quot;</span><span class="p">,</span> <span class="s2">&quot;stay&quot;</span><span class="p">])</span>
<span class="n">simpleWordDF</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>all</td>
    </tr>
    <tr>
      <th>1</th>
      <td>and</td>
    </tr>
    <tr>
      <th>2</th>
      <td>at</td>
    </tr>
    <tr>
      <th>3</th>
      <td>boys</td>
    </tr>
    <tr>
      <th>4</th>
      <td>girls</td>
    </tr>
    <tr>
      <th>5</th>
      <td>home</td>
    </tr>
    <tr>
      <th>6</th>
      <td>kids</td>
    </tr>
    <tr>
      <th>7</th>
      <td>not</td>
    </tr>
    <tr>
      <th>8</th>
      <td>stay</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">simpleWordDF</span><span class="p">,</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>_all</th>
      <th>_and</th>
      <th>_at</th>
      <th>_boys</th>
      <th>_girls</th>
      <th>_home</th>
      <th>_kids</th>
      <th>_not</th>
      <th>_stay</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="word-embeddings">
<h4>Word Embeddings<a class="headerlink" href="#word-embeddings" title="Permalink to this headline">¶</a></h4>
<p>One-Hot-Encoding of words suffer from crucial drawbacks:</p>
<ol class="simple">
<li><p>The vectors are usually very long - there length is given by the number of words in the vocabulary. Moreover, the vectors are quite sparse, since the set of words appearing in one document is usually only a very small part of the set of all words in the vocabulary.</p></li>
<li><p>Semantic relations between words are not modelled. This means that in this model there is no information about the fact that word <em>car</em> is more related to word <em>vehicle</em> than to word <em>lake</em>.</p></li>
<li><p>In the BoW-model of documents word order is totally ignored. E.g. the model can not distinguish if word <em>not</em> appeared immediately before word <em>good</em> or before word <em>bad</em>.</p></li>
</ol>
<p>All of these drawbacks can be solved by applying <em>Word Empeddings</em> and by the way the resulting <em>Word Empeddings</em> are passed e.g. to the input of Recurrent Neural Networks, Convolutional Neural Networks or Transformers (see later chapters of this lecture).</p>
<p>A Word-Embedding maps each word to a dense numeric vector of relatively small size (typical length is 200). The main advantage of these word vectors is that, vectors of similar words are close together in the Euclidean space, whereas vectors of unrelated words are far apart from each other. Word Embeddings are learned from large text-corpora (e.g. the entire Wikipedia) by applying Neural Networks. Learned Word Embeddings are available online. For example the <a class="reference external" href="https://fasttext.cc/">FastText project</a> provides Word-Embeddings for 157 different languages.</p>
</div>
<div class="section" id="bag-of-word-modell-of-documents">
<h4>Bag of Word Modell of documents<a class="headerlink" href="#bag-of-word-modell-of-documents" title="Permalink to this headline">¶</a></h4>
<p>The conventional model for representing texts of arbitrary length as numeric vectors, is the <strong>Bag-of-Words</strong> model.
In this model each word of the underlying vocabulary corresponds to one column and each document (text) corresponds to a single row of a matrix. The entry in row <span class="math notranslate nohighlight">\(i\)</span>, column <span class="math notranslate nohighlight">\(j\)</span> is just the frequency of word <span class="math notranslate nohighlight">\(j\)</span> in document <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>For example, assume, that we have only two documents</p>
<ul class="simple">
<li><p>Document 1: <em>not all kids stay at home</em></p></li>
<li><p>Document 2: <em>all boys and girls stay not at home</em></p></li>
</ul>
<p>The BoW model of these documents is then</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>all</p></th>
<th class="head"><p>and</p></th>
<th class="head"><p>at</p></th>
<th class="head"><p>boys</p></th>
<th class="head"><p>girls</p></th>
<th class="head"><p>home</p></th>
<th class="head"><p>kids</p></th>
<th class="head"><p>not</p></th>
<th class="head"><p>stay</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Document 1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>Document 2</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;not all kids stay at home.&#39;</span><span class="p">,</span>
          <span class="s1">&#39;all boys and girls stay not at home.&#39;</span><span class="p">,</span>
         <span class="p">]</span>
<span class="n">BoW</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;all&#39;, &#39;and&#39;, &#39;at&#39;, &#39;boys&#39;, &#39;girls&#39;, &#39;home&#39;, &#39;kids&#39;, &#39;not&#39;, &#39;stay&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BoW</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1, 0, 1, 0, 0, 1, 1, 1, 1],
       [1, 1, 1, 1, 1, 1, 0, 1, 1]])
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Lecture"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="00BasicConcepts.html" title="previous page">Basic Concepts of Data Mining and Machine Learning</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Prof. Dr. Johannes Maucher<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>