{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you will learn:\n",
    "* Access and preprocess Data\n",
    "* Evaluation metrics for regression\n",
    "* Gradient Boosting Regression\n",
    "* Determine feature importance from Gradient Boosting Regression (ensemble methods in general)\n",
    "* Configure training- and testdata\n",
    "* Evaluation curves for hyperparameter optimizsation\n",
    "* Gridsearch and Randomsearch for hyperparameter optimization\n",
    "* Processing Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task1:** In this notebook *Gradient Boosting Regression* is demonstrated by the example *rental bike prediction*. The corresponding dataset has already been described in notebook [05Optimisation.ipynb](../Lecture/05Optimisation.ipynb). Read this dataset into a pandas dataframe and display it's head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:31:03.804630Z",
     "start_time": "2018-03-02T10:31:03.747325Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:** Calculate descriptive statistics of the generated dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:30:12.531797Z",
     "start_time": "2018-03-02T10:30:12.478787Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:** Columns 1 (season) to 11 (windspeed) are used as features. The target variable is the last column, i.e. the total count of rental bike per day. Prepare training- and test-data, with a split-ratio of $0.7/0.3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:46:49.642566Z",
     "start_time": "2018-03-02T10:46:49.632824Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:** Apply the training-partition to train a `GradientBoostingRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:47:02.789455Z",
     "start_time": "2018-03-02T10:47:01.223283Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics for Regression\n",
    "Regression models can be scored by a variety of metrics. [Regression scores in scikit-learn](http://scikit-learn.org/stable/modules/model_evaluation.html) are \n",
    "\n",
    "* mean absolute error (MAE)\n",
    "* mean squared error (MSE)\n",
    "* median absolute error (MEDE)\n",
    "* coefficient of determination ($R^2$) \n",
    "\n",
    "If $y_i$ is the predicted value for the i.th element and $r_i$ is it's true value, then these metrics are defined as follows:\n",
    "$$\n",
    "\\begin{array}[lcl]\n",
    " NMAE & = &   \\frac{1}{N}\\sum\\limits_{i=1}^N |y_i-r_i| \\\\\n",
    " MSE & = &   \\frac{1}{N}\\sum\\limits_{i=1}^N (y_i-r_i)^2  \\\\\n",
    " MEDE & = &  median\\left( \\; |y_i-r_i|, \\; \\forall \\; i \\; \\in [1,..,N]\\right) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "R^2  =  1- \\frac{SS_e}{SS_r}, \\quad \\mbox{ with } SS_e=\\sum_{i=1}^N(r_i-y_i)^2, \\quad  SS_r=\\sum_{i=1}^N(r_i-\\overline{r})^2 \\quad \\mbox { and } \\quad \\overline{r}=\\frac{1}{N} \\sum_{i=1}^N r_i\n",
    "$$\n",
    "\n",
    "Another frequently used regression metric is the **Root Mean Squared Logarithmic Error (RMSLE)**, which is caluclated as follows:\n",
    "\n",
    "$$\n",
    "RMSLE = \\sqrt{\\frac{1}{N} \\sum\\limits_{i=1}^N(\\ln(r_i)-\\ln(y_i))^2}\n",
    "$$\n",
    "\n",
    "For RMSLE there is no explicit scoring function in scikit-learn, but it can be easily computed via the NMSE-function. The RMSLE is well suited for the case that the error (i.e. the difference between $y_i$ and $r_i$) increases with the values of $r_i$. Then large errors at high values of $r_i$ are weighted less by RMSLE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:47:16.660105Z",
     "start_time": "2018-03-02T10:47:16.646768Z"
    }
   },
   "outputs": [],
   "source": [
    "def determineRegressionMetrics(y_test,y_pred,title=\"\"):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mad = mean_absolute_error(y_test, y_pred)\n",
    "    #rmsle=np.sqrt(mean_squared_error(np.log(y_test+1),np.log(y_pred+1)))\n",
    "    r2=r2_score(y_test, y_pred)\n",
    "    med=median_absolute_error(y_test, y_pred)\n",
    "    evs = explained_variance_score(y_test, y_pred) \n",
    "    print(title)\n",
    "    print(\"Mean absolute error =\", round(mad, 2))\n",
    "    print(\"Mean squared error =\", round(mse, 2))\n",
    "    print(\"Median absolute error =\", round(med, 2))\n",
    "    print(\"R2 score =\", round(r2, 2))\n",
    "    #print \"Root Mean Squared Logarithmic Error =\",rmsle\n",
    "    print(\"Explained variance score =\", round(evs, 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5:** Calculate the learned model's prediction on the test-partition. Use the provided function `determineRegressionMetrics` for calculating all the defined performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:47:14.713218Z",
     "start_time": "2018-03-02T10:47:14.683415Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6:** Apply the provided function `plot_feature_importances` for visualizing the feature importances of the learned model. These feature importances can be obtained from the `feature_importances_`-attribute of the learned `GradientBoostingRegressor`-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:47:40.191269Z",
     "start_time": "2018-03-02T10:47:40.173116Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_feature_importances(feature_importances, title, feature_names,std=\"None\"):\n",
    "    \n",
    "    # Normalize the importance values \n",
    "    feature_importances = 100.0 * (feature_importances / max(feature_importances))\n",
    "    if std==\"None\":\n",
    "        std=np.zeros(len(feature_importances))\n",
    "\n",
    "    # Sort the values and flip them\n",
    "    index_sorted = np.flipud(np.argsort(feature_importances))\n",
    "\n",
    "    # Arrange the X ticks\n",
    "    pos = np.arange(index_sorted.shape[0]) + 0.5\n",
    "\n",
    "    # Plot the bar graph\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.bar(pos, feature_importances[index_sorted], align='center',alpha=0.5,yerr=100*std[index_sorted])\n",
    "    plt.xticks(pos, feature_names[index_sorted])\n",
    "    plt.ylabel('Relative Importance')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:47:43.707732Z",
     "start_time": "2018-03-02T10:47:43.693751Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7:** Visualize the true and the predicted output-value for a range within the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:47:54.230080Z",
     "start_time": "2018-03-02T10:47:53.978988Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8:** For the following `GradientBoosting`-hyperparameter ranges, determine the `validation_curve` (scikit-learn function) and plot the curve using the `plot_evaluation_curve()`-function, which is defined in module `utilsJM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:48:24.103854Z",
     "start_time": "2018-03-02T10:48:24.099546Z"
    }
   },
   "outputs": [],
   "source": [
    "estimator_range=np.arange(20,330,50)\n",
    "lr_range=np.arange(0.02,0.2,0.02)\n",
    "loss=['ls', 'lad', 'huber', 'quantile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-02T10:49:30.972464Z",
     "start_time": "2018-03-02T10:48:29.674966Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T08:35:52.220459Z",
     "start_time": "2018-03-01T08:35:40.703452Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T08:36:16.440682Z",
     "start_time": "2018-03-01T08:36:05.451713Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 9:** Define a hyperparameter grid, by combining the hyperparameter-ranges `estimator_range` and `lr_range`. The hyperparameter grid is implemented as a dictionary, whose keys are the name of the hyperparameters and whose values are the corresponding parameter ranges. Apply *scikit-learn's* `GridSearchCV`-module to find the best combination of estimator-number and learning-rate. Repeat this experiment by replacing `GridSearchCV` with `RandomizedSearchCV`. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T08:37:09.181482Z",
     "start_time": "2018-03-01T08:37:09.176395Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T08:38:08.582105Z",
     "start_time": "2018-03-01T08:38:08.576222Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
