{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Fahrzeugdaten\n",
    "\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 28.06.2021\n",
    "\n",
    "\n",
    "## Lernziele:\n",
    "In diesem Notebook sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Datenimport aus .csv\n",
    "* Explorative Datenanalysen (EDA)\n",
    "* Datenvisualisierung mit Matplotlib und plotly\n",
    "* Überwachtes Lernen eines Klassifikationsmodells\n",
    "* Überwachtes Lernen eines Regressionsmodells\n",
    "* Evaluation von Klassifikationsmodellen\n",
    "* Evaluation von Regressionsmodellen\n",
    "* Kreuzvalidierung\n",
    "* Hyperparameteroptimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenzugriff\n",
    "\n",
    "\n",
    "Die Daten sollen aus der Datei `Fahrzeuginformationen.csv` eingelesen werden. Das benötigte File liegt im Verzeichnis `../Data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Laden Sie die .csv-Datei in einen Pandas Dataframe. \n",
    "\n",
    "2. Zeigen Sie für den angelegten Dataframe \n",
    "    * die ersten 10 Zeilen\n",
    "    * die Größe (Anzahl Zeilen und Anzahl Spalten)\n",
    "    * die Anzahl der NaNs pro Spalte\n",
    "    an. \n",
    "3. Zeigen Sie mit der Pandas-Dataframe Methode `info()`, den Stellen Sie sicher, dass die Spalte `CO2-Emissionen` ein numerischer Typ (float) ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "81c8b08e-3c23-41ac-8e21-255dbda97cae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV, GroupKFold\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import plot_roc_curve, plot_confusion_matrix, classification_report\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f85ce87e-60b5-47a0-9c0e-dec064834222",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Exploration\n",
    "1. Zeigen Sie für alle Spalten die Anzahl der unterschiedlichen Werte in dieser Spalte an.\n",
    "2. Benutzen Sie die Pandas Dataframe Methode `describe()` um sämtliche deskriptiven Statistiken anzuzeigen.\n",
    "3. Legen Sie eine Liste `numeric_features` an, welche nur die Spaltennamen der numerischen Spalten enthält.\n",
    "4. Schreiben Sie die Namen aller nicht-numerischen Spalten in eine Liste `categoric_features`.\n",
    "5. Visualisieren Sie für die Spalten `HST_Benennung`, `Neupreis Brutto`, `CO2-Emissionen` und `Produktgruppe` die Verteilung der Werte in einem Barplot bzw. Histogramm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f7590e2b-4176-4c3c-8b05-833ef4513b20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning 1: Produktgruppenbestimmung\n",
    "\n",
    "In diesem Abschnitt soll ein Klassifikator trainiert werden, welcher anhand von Eingabemerkmalen, wie *Breite*, *Höhe*, *Gewicht* usw. das zugehörige Fahrzeugsegment (`Produktgruppe`) vorhersagt.\n",
    "\n",
    "In diesem Teilversuch sollen als Eingabemerkmale die zuvor in `numeric_features` definierten Spalten und die nicht-numerischen Spalten `Antrieb`, `Kraftstoffart`, `KSTA Motor` verwendet werden. Die Zielvariable (Ausgabe) stellt die Spalte `Produktgruppe` dar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auswahl der relevanten Merkmale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "63e5b2ec-17c0-4494-b5ab-a8a7a203d881",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Data Encoding\n",
    "\n",
    "1. Kategoriale Merkmale ohne Ordnungsrelation (=nominale Merkmale) müssen One-Hot-Encodiert werden. Führen Sie für die drei categorialen Merkmale ein One-Hot-Encoding mit dem [scikit-learn LabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) durch.\n",
    "2. Fügen Sie die one-hot-encodierten Spalten mit den numerischen Spalten zusammen. Weisen Sie die entsprechende Eingabedatenmatrix einem 2-dimensionalen numpy-array `X` zu. \n",
    "3. Führen Sie auf die Zielvariable `Produktgruppe` ein Label-Encoding mit [scikit-learn LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder) aus. Weisen Sie diese Daten dem 1-dimensionalen numpy-array `y` zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1535bdf1-f3a9-4a57-88d2-756af7b52be8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Erzeuge Training- and Testpartition\n",
    "Benutzen Sie die [scikit-learn Methode train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) um `X` und `y` in einer Trainings- und Testpartition aufzuteilen. 30% der Daten soll für das Testen, 70% für das Training benutzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b8a8c080-f89e-4b8d-b765-4d6a8ba1c863",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Decision Tree Training, Test and Evaluation\n",
    "1. Trainieren Sie einen [Entscheidungsbaum](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) mit den Trainingsdaten.\n",
    "2. Wenden Sie den gelernten Entscheidungsbaum auf die Testdaten.\n",
    "3. Evaluieren Sie die Qualität des Entscheidungsbaumes indem Sie \n",
    "     - einen [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) erzeugen. \n",
    "     - die [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html) plotten.\n",
    " \n",
    " Interpretieren Sie das Ergebnis.\n",
    " \n",
    "4. Führen Sie eine [10-fache Kreuzvalidierung](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) des Entscheidungsbaumes mit den Daten `X` und `y` aus. Interpretieren Sie das Ergebnis.\n",
    "5. Bestimmen Sie die *Wichtigkeit* der Eingabemerkmale für die Klassifikationsaufgabe, indem Sie auf den in 1.) gelernten DecisionTree das Attribut `feature_importance_` abfragen. Stellen Sie die Werte in einem Barplot dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "af044466-8c3e-4681-b5e2-c248cae1321d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Random Forest Training, Test and Evaluation\n",
    "Wiederholen Sie die Teilaufgaben 1. bis 5. des Entscheidungsbaums für einen [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). Vergelichen Sie die Performance der beiden Verfahren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning 2: Schätzung der CO2-Emission\n",
    "In diesem Teilversuch soll aus den Eingabemerkmalen \n",
    "\n",
    "`\"CCM\",\"HST PS\", \"Anzahl der Türen\", \"Leergewicht\", \"Zuladung\", \"Länge\", \"Breite\", \"Höhe\"`\n",
    "\n",
    "die Zielvariable \n",
    "\n",
    "`CO2-Emissionen`\n",
    "\n",
    "geschätzt werden. Hierzu soll ein möglichst gutes Regressionsmodell trainiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visuelle Korrelationsanalyse\n",
    "1. Stellen Sie für jedes der 8 Eingabemerkmale die Korrelation mit der Zielvariablen visuell in einem Scatterplot dar, in dem das jeweilige Eingabemerkmal auf der x-Achse und die Zielvariable auf der y-Achse aufgetragen wird.\n",
    "2. Diskutieren Sie die Korrelationen. Welche Merkmale korrelieren am stärksten mit der Zielvariable? Erscheint Ihnen das plausibel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_inputcols=[\"CCM\",\"HST PS\", \"Anzahl der Türen\", \"Leergewicht\", \"Zuladung\", \"Länge\", \"Breite\", \"Höhe\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encoding\n",
    "1. Weisen Sie die Matrix der Eingabedaten dem 2-dimensionalen Array `X` und die Zielvariable dem 1-dimensionalen Array `y` zu.\n",
    "2. Führen Sie auf `X` und `y` eine Partitionierung in Trainings- und Testdaten durch, wieder im Verhältnis 70/30.\n",
    "3. Skalieren Sie die Eingabevariablen und die Zielvariable mit dem [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html). Die Skalierung muss sowohl auf Trainings- als auch auf Testdaten ausgeführt werden. Warum darf die Skalierung erst nach dem Split in die beiden Partitionen ausgeführt werden? Worauf ist zu achten? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Test und Evaluation verschiedener Regressionsmodelle\n",
    "\n",
    "Führen Sie die folgenden Teilaufgaben sowohl für ein [Single Layer Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html) als auch für ein [Multi Layer Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) mit 20 Neuronen in der Hidden-Schicht durch. Vergleichen Sie am Ende die Performance der beiden Verfahren.\n",
    "1. Trainieren Sie den Algorithmus mit den Trainingsdaten.\n",
    "2. Wenden Sie das gelernte Modell auf die Testdaten an.\n",
    "3. Evaluieren Sie die Qualität der Modelle, indem Sie auf die vorhergesagten Ausgaben und die wahren Ausgaben die unten gegebene Funktion aufrufen.\n",
    "4. Beschreiben Sie kurz die in der Funktion verwendeten Metriken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineRegressionMetrics(y_test,y_pred,title=\"\"):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mad = mean_absolute_error(y_test, y_pred)\n",
    "    rmsle=np.sqrt(mean_squared_error(np.log(y_test+1),np.log(y_pred+1)))# +1 for avoiding log(0) \n",
    "    r2=r2_score(y_test, y_pred)\n",
    "    med=median_absolute_error(y_test, y_pred)\n",
    "    print(title)\n",
    "    print(\"Mean absolute error =\", round(mad, 2))\n",
    "    print(\"Mean squared error =\", round(mse, 2))\n",
    "    print(\"Median absolute error =\", round(med, 2))\n",
    "    print(\"R2 score =\", round(r2, 2))\n",
    "    print(\"Root Mean Squared Logarithmic Error =\",rmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameteroptimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für ein [Multi Layer Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) soll eine Hyperparameteroptimierung durchgeführt werden. Ziel ist es innerhalb der unten vorgegebenen Wertebereiche für die Hyperparameter `hidden_layer_sizes`, `activation` und `learning_rate` die beste Konfiguration zu finden. Hierzu kann entweder [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) oder [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) eingesetzt werden. GridSearchCV testet einfach alle Konfigurationen durch, benötigt daher aber viel Zeit. RandomizedSearchCV geht heuristisch und damit schneller durch den Suchraum. Wenden Sie eines dieser beiden Verfahren an, um für das unten gegebene Parameter-Grid die optimale Konfiguration zu finden. Welches ist die optimale Konfiguration und zu welchem `neg_mean_absolute_error`  führt diese?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hidden_layer_sizes': [(10,), (20,), (30,), (40,), (50,), (100,), (10, 10)],\n",
       "  'activation': ['logistic', 'tanh', 'relu'],\n",
       "  'learning_rate': ['constant', 'invscaling', 'adaptive']}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'hidden_layer_sizes': [(10,),(20,),(30,),(40,),(50,),(100,),(10,10)], \n",
    "               'activation': [\"logistic\", \"tanh\", \"relu\"], \n",
    "               'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"]}]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "fahrzeug_segmentierung_uebung",
   "notebookOrigID": 628697663431637,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
