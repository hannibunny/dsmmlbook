{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn evaluate and compare Classification Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:09:50.940000Z",
     "start_time": "2018-02-05T14:09:50.924000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import compose\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,MinMaxScaler,normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, KFold\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, f_regression, chi2, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Data\n",
    "\n",
    "In this notebook **classification models** are trained and evaluated by the example application **Heart Disease Prediction**. The task is to determine the presence of a heart disease from 13 input features. The applied dataset is available from [http://archive.ics.uci.edu/ml/datasets/Heart+Disease](http://archive.ics.uci.edu/ml/datasets/Heart+Disease). After downloading and storing the corresponding .csv-file it can be accessed using *Pandas*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:09:53.502000Z",
     "start_time": "2018-02-05T14:09:53.456000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  303\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  num  \n",
       "0    3.0  0.0   6.0    0  \n",
       "1    2.0  3.0   3.0    2  \n",
       "2    2.0  2.0   7.0    1  \n",
       "3    3.0  0.0   3.0    0  \n",
       "4    1.0  0.0   3.0    0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infile=\"../Data/HeartDiseaseCleveland.csv\"\n",
    "indf=pd.read_csv(infile)\n",
    "print(\"Number of rows: \",len(indf))\n",
    "display(indf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features:**\n",
    "\n",
    "1. age: age in years\n",
    "2. sex: sex (1 = male; 0 = female)\n",
    "3. cp: chest pain type \n",
    "    - Value 1: typical angina \n",
    "    - Value 2: atypical angina \n",
    "    - Value 3: non-anginal pain \n",
    "    - Value 4: asymptomatic \n",
    "4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "6. chol: serum cholestoral in mg/dl\n",
    "7. fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "8. restecg: resting electrocardiographic results \n",
    "    - Value 0: normal \n",
    "    - Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) \n",
    "    - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "9. thalach: maximum heart rate achieved\n",
    "10. exang: exercise induced angina (1 = yes; 0 = no)\n",
    "11. oldpeak = ST depression induced by exercise relative to rest\n",
    "12. slope: the slope of the peak exercise ST segment\n",
    "    - Value 1: upsloping \n",
    "    - Value 2: flat \n",
    "    - Value 3: downsloping\n",
    "13. ca: number of major vessels (0-3) colored by flourosopy\n",
    "14. thal: heartrate\n",
    "    - Value 3: normal \n",
    "    - Value 6: fixed defect\n",
    "    - Value 7: reversable defect\n",
    "    \n",
    "    \n",
    "**Feature types**\n",
    "    \n",
    "- Real-valued attributes: 1,4,5,8,10,12\n",
    "- Binary attributes: 2,6,9\n",
    "- Ordered attribute: 11\n",
    "- Nominal attributes: 3,7,13\n",
    "\n",
    "**Target (Class label):** \n",
    "\n",
    "- 0: no disease\n",
    "- 1,2,3,4 degree of disease\n",
    "\n",
    "In this experiment all non-zero classlabels are mapped to 1, i.e. the binary classification just distinguishes disease and no-disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "First, we check, if there are missing values in the dataset. In this case the corresponding rows will be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:19:39.706000Z",
     "start_time": "2018-02-05T14:19:39.690000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        2\n",
      "num         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(indf.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:19:39.706000Z",
     "start_time": "2018-02-05T14:19:39.690000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after deleting rows with missing values:  297\n"
     ]
    }
   ],
   "source": [
    "indf=indf.dropna()\n",
    "print(\"Number of rows after deleting rows with missing values: \",len(indf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split features (first 13 columns) from class label (last column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:19:46.441000Z",
     "start_time": "2018-02-05T14:19:46.425000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 63.    1.    1.  145.  233.    1.    2.  150.    0.    2.3   3.    0.\n",
      "    6. ]\n",
      " [ 67.    1.    4.  160.  286.    0.    2.  108.    1.    1.5   2.    3.\n",
      "    3. ]\n",
      " [ 67.    1.    4.  120.  229.    0.    2.  129.    1.    2.6   2.    2.\n",
      "    7. ]\n",
      " [ 37.    1.    3.  130.  250.    0.    0.  187.    0.    3.5   3.    0.\n",
      "    3. ]]\n",
      "(297, 13)\n"
     ]
    }
   ],
   "source": [
    "featureNames=indf.columns[:-1].tolist()\n",
    "X=indf[featureNames].values\n",
    "yraw=indf[\"num\"].values\n",
    "print(X[:4,:])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, in this experiment a binary classifier shall be implemented, which differentiates the classes *disease* and *no disease*. For this all non-zero values in the class-label column are mapped to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:19:57.785000Z",
     "start_time": "2018-02-05T14:19:57.785000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels of first 4 samples:    [0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "CLIP=True #if True all non-zero classlabels are mapped to 1 (binary classification)\n",
    "y=np.copy(yraw)\n",
    "if CLIP:\n",
    "    y=np.clip(y,a_min=0,a_max=1)\n",
    "print(\"Class labels of first 4 samples:   \",y[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot-Encoding of nominal features\n",
    "The nominal features in columns 2,6 and 12 must be one-hot-encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note} \n",
    "The following code-snippet just demonstrates one-hot-encoding in scikit-learn, in particular the arrangement of one-hot encoded nominal features in the transformed feature matrix. Moreover, the function `convert2OneHotFeatureNames()` can be applied to assign the column names to the transformed data.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of feature array: (297, 20)\n"
     ]
    }
   ],
   "source": [
    "catFeats=[2,6,12]\n",
    "\n",
    "oheTransformer = compose.make_column_transformer(\n",
    "    (OneHotEncoder(categories=\"auto\"), catFeats), remainder=\"passthrough\"\n",
    ")\n",
    "Xoh = oheTransformer.fit_transform(X)\n",
    "print(\"New shape of feature array:\",Xoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:20:04.878000Z",
     "start_time": "2018-02-05T14:20:04.859000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "def convert2OneHotFeatureNames(catFeats,featureNames,X):\n",
    "    '''\n",
    "    catFeats:       List, which contains the indices of the nominal features\n",
    "    featureNames:   List of original featureNames\n",
    "    X:              2-d Numpy Array containing numerical feature-values before one-hot-encoding\n",
    "    \n",
    "    function returns onehotFeatureNames, which are the names of the columns of X after one-hot-encoding\n",
    "    '''\n",
    "    nonCatFeatureNames=[f for (i,f) in enumerate(featureNames) if i not in catFeats]\n",
    "    #print nonCatFeatureNames\n",
    "    onehotFeatureNames=[]\n",
    "    for c in catFeats:\n",
    "        vals=np.unique(X[:,c])\n",
    "        fname=featureNames[c]\n",
    "        #print \"Values of nominal feature in column %d:  \"%(c),vals\n",
    "        for v in vals:\n",
    "            onehotFeatureNames.append(fname+\"=\"+str(v))\n",
    "    onehotFeatureNames.extend(nonCatFeatureNames)\n",
    "    return onehotFeatureNames\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rearrangement of columns becomes obvious if the original feature matrix and the transformed feature matrix are displayed as Pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:20:09.519000Z",
     "start_time": "2018-02-05T14:20:09.472000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix before One-Hot-Encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  \n",
       "0    3.0  0.0   6.0  \n",
       "1    2.0  3.0   3.0  \n",
       "2    2.0  2.0   7.0  \n",
       "3    3.0  0.0   3.0  \n",
       "4    1.0  0.0   3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "featureDF=pd.DataFrame(data=X,columns=featureNames)\n",
    "print(\"Feature matrix before One-Hot-Encoding:\")\n",
    "display(featureDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:20:14.809000Z",
     "start_time": "2018-02-05T14:20:14.762000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix after One-Hot-Encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp=1.0</th>\n",
       "      <th>cp=2.0</th>\n",
       "      <th>cp=3.0</th>\n",
       "      <th>cp=4.0</th>\n",
       "      <th>restecg=0.0</th>\n",
       "      <th>restecg=1.0</th>\n",
       "      <th>restecg=2.0</th>\n",
       "      <th>thal=3.0</th>\n",
       "      <th>thal=6.0</th>\n",
       "      <th>thal=7.0</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cp=1.0  cp=2.0  cp=3.0  cp=4.0  restecg=0.0  restecg=1.0  restecg=2.0  \\\n",
       "0     1.0     0.0     0.0     0.0          0.0          0.0          1.0   \n",
       "1     0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
       "2     0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
       "3     0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
       "4     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
       "\n",
       "   thal=3.0  thal=6.0  thal=7.0   age  sex  trestbps   chol  fbs  thalach  \\\n",
       "0       0.0       1.0       0.0  63.0  1.0     145.0  233.0  1.0    150.0   \n",
       "1       1.0       0.0       0.0  67.0  1.0     160.0  286.0  0.0    108.0   \n",
       "2       0.0       0.0       1.0  67.0  1.0     120.0  229.0  0.0    129.0   \n",
       "3       1.0       0.0       0.0  37.0  1.0     130.0  250.0  0.0    187.0   \n",
       "4       1.0       0.0       0.0  41.0  0.0     130.0  204.0  0.0    172.0   \n",
       "\n",
       "   exang  oldpeak  slope   ca  \n",
       "0    0.0      2.3    3.0  0.0  \n",
       "1    1.0      1.5    2.0  3.0  \n",
       "2    1.0      2.6    2.0  2.0  \n",
       "3    0.0      3.5    3.0  0.0  \n",
       "4    0.0      1.4    1.0  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "onehotFeatureNames=convert2OneHotFeatureNames(catFeats,featureNames,X)\n",
    "oneHotFeatureDF=pd.DataFrame(data=Xoh,columns=onehotFeatureNames)\n",
    "#oneHotFeatureDF=pd.DataFrame(data=Xoh)\n",
    "print(\"Feature matrix after One-Hot-Encoding:\")\n",
    "display(oneHotFeatureDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append class label to one-hot-encoded data and write dataframe to .csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:20:18.482000Z",
     "start_time": "2018-02-05T14:20:18.411000+01:00"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp=1.0</th>\n",
       "      <th>cp=2.0</th>\n",
       "      <th>cp=3.0</th>\n",
       "      <th>cp=4.0</th>\n",
       "      <th>restecg=0.0</th>\n",
       "      <th>restecg=1.0</th>\n",
       "      <th>restecg=2.0</th>\n",
       "      <th>thal=3.0</th>\n",
       "      <th>thal=6.0</th>\n",
       "      <th>thal=7.0</th>\n",
       "      <th>...</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cp=1.0  cp=2.0  cp=3.0  cp=4.0  restecg=0.0  restecg=1.0  restecg=2.0  \\\n",
       "0     1.0     0.0     0.0     0.0          0.0          0.0          1.0   \n",
       "1     0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
       "2     0.0     0.0     0.0     1.0          0.0          0.0          1.0   \n",
       "3     0.0     0.0     1.0     0.0          1.0          0.0          0.0   \n",
       "4     0.0     1.0     0.0     0.0          0.0          0.0          1.0   \n",
       "\n",
       "   thal=3.0  thal=6.0  thal=7.0  ...  sex  trestbps   chol  fbs  thalach  \\\n",
       "0       0.0       1.0       0.0  ...  1.0     145.0  233.0  1.0    150.0   \n",
       "1       1.0       0.0       0.0  ...  1.0     160.0  286.0  0.0    108.0   \n",
       "2       0.0       0.0       1.0  ...  1.0     120.0  229.0  0.0    129.0   \n",
       "3       1.0       0.0       0.0  ...  1.0     130.0  250.0  0.0    187.0   \n",
       "4       1.0       0.0       0.0  ...  0.0     130.0  204.0  0.0    172.0   \n",
       "\n",
       "   exang  oldpeak  slope   ca  num  \n",
       "0    0.0      2.3    3.0  0.0    0  \n",
       "1    1.0      1.5    2.0  3.0    2  \n",
       "2    1.0      2.6    2.0  2.0    1  \n",
       "3    0.0      3.5    3.0  0.0    0  \n",
       "4    0.0      1.4    1.0  0.0    0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oneHotDFall=oneHotFeatureDF\n",
    "oneHotDFall[\"num\"]=yraw\n",
    "display(oneHotDFall.head())\n",
    "oneHotDFall.to_csv(\"../Data/HeartDiseaseClevelandEncoded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note} \n",
    "Above one-hot-encoding as provided by scikit-learn has been demonstrated. We will apply this function later on, when we build scikit-learn pipelines. The drawback of the scikit-learn function is that it doesn't regard column-names. In order to map the new columns to meaningful names, we implemented our own function `convert2OneHotFeatureNames()`. A better alternative would be the pandas function `get_dummies()`. It provides one-hot-encoding and a corresponding extension of column-names. The use of `get_dummies()` is demonstrated in the code-cell below. However, this pandas-version of One-Hot-Encoding can not be applied within scikit-learn processsing chains, which will be demonstrated below:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative: One-Hot-Encoding with [pandas.get_dummies()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  \n",
       "0    3.0  0.0   6.0  \n",
       "1    2.0  3.0   3.0  \n",
       "2    2.0  2.0   7.0  \n",
       "3    3.0  0.0   3.0  \n",
       "4    1.0  0.0   3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>restecg_0.0</th>\n",
       "      <th>restecg_1.0</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  trestbps   chol  fbs  thalach  exang  oldpeak  slope   ca  \\\n",
       "0    63.0  1.0     145.0  233.0  1.0    150.0    0.0      2.3    3.0  0.0   \n",
       "1    67.0  1.0     160.0  286.0  0.0    108.0    1.0      1.5    2.0  3.0   \n",
       "2    67.0  1.0     120.0  229.0  0.0    129.0    1.0      2.6    2.0  2.0   \n",
       "3    37.0  1.0     130.0  250.0  0.0    187.0    0.0      3.5    3.0  0.0   \n",
       "4    41.0  0.0     130.0  204.0  0.0    172.0    0.0      1.4    1.0  0.0   \n",
       "..    ...  ...       ...    ...  ...      ...    ...      ...    ...  ...   \n",
       "297  57.0  0.0     140.0  241.0  0.0    123.0    1.0      0.2    2.0  0.0   \n",
       "298  45.0  1.0     110.0  264.0  0.0    132.0    0.0      1.2    2.0  0.0   \n",
       "299  68.0  1.0     144.0  193.0  1.0    141.0    0.0      3.4    2.0  2.0   \n",
       "300  57.0  1.0     130.0  131.0  0.0    115.0    1.0      1.2    2.0  1.0   \n",
       "301  57.0  0.0     130.0  236.0  0.0    174.0    0.0      0.0    2.0  1.0   \n",
       "\n",
       "     cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  restecg_2.0  \\\n",
       "0         1       0       0       0            0            0            1   \n",
       "1         0       0       0       1            0            0            1   \n",
       "2         0       0       0       1            0            0            1   \n",
       "3         0       0       1       0            1            0            0   \n",
       "4         0       1       0       0            0            0            1   \n",
       "..      ...     ...     ...     ...          ...          ...          ...   \n",
       "297       0       0       0       1            1            0            0   \n",
       "298       1       0       0       0            1            0            0   \n",
       "299       0       0       0       1            1            0            0   \n",
       "300       0       0       0       1            1            0            0   \n",
       "301       0       1       0       0            0            0            1   \n",
       "\n",
       "     thal_3.0  thal_6.0  thal_7.0  \n",
       "0           0         1         0  \n",
       "1           1         0         0  \n",
       "2           0         0         1  \n",
       "3           1         0         0  \n",
       "4           1         0         0  \n",
       "..        ...       ...       ...  \n",
       "297         0         0         1  \n",
       "298         0         0         1  \n",
       "299         0         0         1  \n",
       "300         0         0         1  \n",
       "301         1         0         0  \n",
       "\n",
       "[297 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indfF=indf.drop(columns=\"num\")\n",
    "display(indfF.head())\n",
    "indfFOH=pd.get_dummies(indfF,columns=[\"cp\",\"restecg\",\"thal\"])\n",
    "display(indfFOH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test\n",
    "\n",
    "Simple split in training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:27:20.395000Z",
     "start_time": "2018-02-05T14:27:20.379000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Pipeline\n",
    "The entire Data Mining process usually comprises a sequence of modules, e.g: \n",
    "\n",
    "```data access -> cleaning -> feature selection -> transformations -> modelling -> visualisation -> evaluatio```\n",
    "\n",
    "\n",
    "In scikit-learn such sequences of modules can comfortably be encapsulated within a single [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline). As shown in the code-snippet below, a Pipeline-object can be configured as a sequence of other scikit-learn objects. The restriction is that all but the last module in a pipeline must be of **Transformer**-type. All *Transformers* have a `.fit()`-method for training and a `.transform()`-method to transform data. The last module in the sequence is an **Estimator**-type. All *Estimators* have a `.fit()`-method for training and a `.predict()` method to estimate an output for the given input data. The main benefits of the`**Pipeline**-class are:\n",
    "\n",
    "* For training the `.fit()`-method must be envoked only once to fit a whole sequence of modules in the pipeline.\n",
    "* After training the `.predict()`-method must also be envoked only once per pipeline.\n",
    "* Parameter optimisation, e.g. by Grid-Search can be performed over all parameters in the pipeline. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:27:33.504000Z",
     "start_time": "2018-02-05T14:27:33.488000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "catFeats=[2,6,12]\n",
    "pipe = Pipeline([('oneHot', compose.make_column_transformer((OneHotEncoder(categories=\"auto\"), catFeats), \n",
    "                                                            remainder=\"passthrough\")),\n",
    "                 ('stdSc', StandardScaler(with_mean=True)),\n",
    "                 #('pca', PCA(n_components=2)),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:28:06.049000Z",
     "start_time": "2018-02-05T14:28:05.908000+01:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('oneHot',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  [2, 6, 12])])),\n",
       "                ('stdSc', StandardScaler()),\n",
       "                ('clf', LogisticRegression(C=0.1, random_state=1))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics for classifiers\n",
    "#### The simple way: Accuracy\n",
    "The accuracy of the classifier in the context of all modules in the pipeline can be calculated by envoking the `.score(X,y)`-function. The function passes data $X$ through all modules of the pipeline. By comparing the outputs of the last module (classifer) to the true labels $y$ the accuracy is calculated. The same result can be obtained by first envoking `y_p=pipe.predict(X,y)` followed by `accuracy_score(y_p,y)` (see below).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:28:44.611000Z",
     "start_time": "2018-02-05T14:28:44.595000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.855\n",
      "Test Accuracy: 0.800\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy: %.3f' % pipe.score(X_train, y_train)) \n",
    "print('Test Accuracy: %.3f' % pipe.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix, Precision, Recall, F1-Score\n",
    "For a more thorough analysis of a classifier, determination of accuracy alone is not sufficient. The metrics defined below provide more subtle information on correct and erroneous events. All of the defined evaluation metrics can be obtained from the confusion matrix. For a binary classifier, the confusion matrix is depicted below. For a *K*-class classifier, the confusion matrix has size $K \\times K$. The rows correspond to the true labels, the columns to the predicted labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:28:51.411000Z",
     "start_time": "2018-02-05T14:28:51.395000+01:00"
    }
   },
   "source": [
    "<img src=\"https://maucher.home.hdm-stuttgart.de/Pics/confusionMat.png\" style=\"width:300px\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:** The rate of overall correct classifications: \n",
    "\n",
    "$$\n",
    "ACC=\\frac{TP+TN}{FP+FN+TP+TN}\n",
    "$$\n",
    "\n",
    "**Error Rate:** The rate of overall erroneous classifications: \n",
    "\n",
    "$$\n",
    "ERR=\\frac{FP+FN}{FP+FN+TP+TN}\n",
    "$$\n",
    "\n",
    "**False Positive Rate:** \n",
    "\n",
    "$$\n",
    "FPR=\\frac{FP}{FP+TN}\n",
    "$$\n",
    "\n",
    "**True Positive Rate:** \n",
    "\n",
    "$$\n",
    "TPR=\\frac{TP}{FN+TP}\n",
    "$$\n",
    "\n",
    "**Precision:** How much of the samples, which have been classified as *positive* are actual *positive* \n",
    "\n",
    "$$\n",
    "PRE=\\frac{TP}{FP+TP}\n",
    "$$ \n",
    "\n",
    "**Recall:**(=TPR): How much of the true *positive* samples has been classified as *positive* \n",
    "\n",
    "$$\n",
    "REC=\\frac{TP}{FN+TP}\n",
    "$$\n",
    "\n",
    "**F1-Score:** Harmonic mean of Precision and Recall \n",
    "\n",
    "$$\n",
    "F1=2\\frac{PRE \\cdot REC }{PRE + REC}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate these performance-metrics on the test-data, we first determine the model's prediction on the test-data. Then the corresponding scikit-learn metric-functions are applied as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:29:01.612000Z",
     "start_time": "2018-02-05T14:29:01.612000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "y_pred=pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:28:56.428000Z",
     "start_time": "2018-02-05T14:28:56.428000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function just plots the confusion-matrix in a nicer way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:29:13.223000Z",
     "start_time": "2018-02-05T14:29:13.223000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confmat):\n",
    "    fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            ax.text(x=j, y=i,\n",
    "            s=confmat[i, j],va='center', ha='center')\n",
    "    plt.xlabel('predicted label')\n",
    "    plt.ylabel('true label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:29:16.473000Z",
     "start_time": "2018-02-05T14:29:16.333000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43  5]\n",
      " [13 29]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Users/johannes/gitprojects/dsmmlbook/mlbook/_build/jupyter_execute/Lecture/03ClassificationPipe_43_1.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)\n",
    "plot_confusion_matrix(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:29:22.900000Z",
     "start_time": "2018-02-05T14:29:22.900000+01:00"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:        0.8\n",
      "Precision:       [0.76785714 0.85294118]\n",
      "Recall:          [0.89583333 0.69047619]\n",
      "F1-Score:        [0.82692308 0.76315789]\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:       \",accuracy_score(y_test, y_pred))\n",
    "print (\"Precision:      \",precision_score(y_test, y_pred,average=None))\n",
    "print (\"Recall:         \",recall_score(y_test, y_pred,average=None))\n",
    "print (\"F1-Score:       \",f1_score(y_test, y_pred,average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These metrics can also be calculated in one step, by applying the `classification_report()`-method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83        48\n",
      "           1       0.85      0.69      0.76        42\n",
      "\n",
      "    accuracy                           0.80        90\n",
      "   macro avg       0.81      0.79      0.80        90\n",
      "weighted avg       0.81      0.80      0.80        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the Recall of both classes one can conclude, that this model is better in finding the true *no-disease* cases, than in finding the true *disease*-cases. It would be better in the other way around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro averages of precision and recall: \t 0.81 0.7949999999999999\n",
      "Weighted averages of precision and recall: \t 0.8073333333333333 0.802\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro averages of precision and recall: \\t\",(0.77+0.85)/2, (0.9+0.69)/2)\n",
    "print(\"Weighted averages of precision and recall: \\t\",(48*0.77+42*0.85)/90, (48*0.9+42*0.69)/90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Receiver Operating Curves\n",
    "Receiver Operating Curves (ROC) visualize the performance of a binary classifier as its discrimination threshold is varied.\n",
    "ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the *ideal* point - a false positive rate of zero, and a true positive rate of one. This is not very realistic. A quantitative performance-measure based on ROC is the Area Under Curve (AUC). The larger the AUC the better the classifier. The maximum value of AUC is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/68/9tltm6l520v0stj3qjlc5v9w0000gn/T/ipykernel_31179/450551658.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmean_tpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsmmlbook/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dsmmlbook/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# None is the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0;34m\"Setting a random_state has no effect since shuffle is \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;34m\"False. You should leave \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Setting a random_state has no effect since shuffle is False. You should leave random_state to its default (None), or set shuffle=True."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "pipe = Pipeline([('scl', StandardScaler()),\n",
    "                 ('clf', LogisticRegression(penalty='l2',random_state=0,C=100.0))])\n",
    "\n",
    "splits=5\n",
    "cv = StratifiedKFold(n_splits=splits,random_state=1)\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "for i, (train, test) in enumerate(cv.split(X_train,y_train)):\n",
    "    pipe.fit(X_train[train],y_train[train])\n",
    "    probas = pipe.predict_proba(X_train[test])    \n",
    "    fpr, tpr, thresholds = roc_curve(y_train[test],probas[:, 1],pos_label=1)\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr,tpr,lw=1,label='ROC fold %d (area = %0.2f)'% (i+1, roc_auc))\n",
    "plt.plot([0, 1],[0, 1],linestyle='--',color=(0.6, 0.6, 0.6),label='random guessing')\n",
    "mean_tpr /= splits#len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--',label='mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "plt.plot([0, 0, 1],[0, 1, 1],lw=2,linestyle=':',color='black',label='perfect performance')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.title('Receiver Operator Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "Cross-Validation has been described in [section Basic Concepts of Machine Learning](00BasicConcepts.ipynb). The code-cells below demonstrate how crossvalidation can be implemeted with Scikit-Learn. The first option, which applied the `StratifiedKFold()`-class provides more control within the individual iterations of CV. The second option, using `cross_val_score()` is the easier to implement, since only one line of code is required to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267.3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]/10*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:33:16.361000Z",
     "start_time": "2018-02-05T14:33:16.283000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.: [144 123], Acc: 0.867\n",
      "Fold: 2, Class dist.: [144 123], Acc: 0.833\n",
      "Fold: 3, Class dist.: [144 123], Acc: 0.833\n",
      "Fold: 4, Class dist.: [144 123], Acc: 0.933\n",
      "Fold: 5, Class dist.: [144 123], Acc: 0.867\n",
      "Fold: 6, Class dist.: [144 123], Acc: 0.767\n",
      "Fold: 7, Class dist.: [144 123], Acc: 0.867\n",
      "Fold: 8, Class dist.: [144 124], Acc: 0.897\n",
      "Fold: 9, Class dist.: [144 124], Acc: 0.724\n",
      "Fold: 10, Class dist.: [144 124], Acc: 0.828\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10,random_state=1)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold.split(X,y)):\n",
    "    pipe.fit(X[train], y[train])\n",
    "    score = pipe.score(X[test], y[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1,np.bincount(y[train]), score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the example above, the `StratifiedKFold()`-class asserts, that the class-distribution in each cross-validation is the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same result can be obtained by applying the `cross_val_score`-function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:34:48.520000Z",
     "start_time": "2018-02-05T14:34:48.427000+01:00"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.86666667 0.83333333 0.83333333 0.93333333 0.86666667 0.76666667\n",
      " 0.86666667 0.89655172 0.72413793 0.82758621]\n",
      "CV accuracy: 0.841 +/- 0.058\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=pipe,X=X, y=y,cv=10)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance without One-Hot-Encoding\n",
    "Next, we like to find out, if the same linear classification algorithm - `LogisticRegression` - performs better, if One-Hot-Encoding is ignored. For this we remove the One-Hot-Encoder processing from the pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:35:15.377000Z",
     "start_time": "2018-02-05T14:35:15.377000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([('stdSc', StandardScaler(with_mean=True)),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:35:55.862000Z",
     "start_time": "2018-02-05T14:35:55.846000+01:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('stdSc', StandardScaler()),\n",
       "                ('clf', LogisticRegression(C=0.1, random_state=1))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:36:40.864000Z",
     "start_time": "2018-02-05T14:36:40.864000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "y_pred2=pipe2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:36:44.901000Z",
     "start_time": "2018-02-05T14:36:44.755000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  4]\n",
      " [12 30]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Users/johannes/gitprojects/dsmmlbook/mlbook/_build/jupyter_execute/Lecture/03ClassificationPipe_61_1.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mat2 = confusion_matrix(y_test, y_pred2)\n",
    "print(confusion_mat2)\n",
    "plot_confusion_matrix(confusion_mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:36:50.441000Z",
     "start_time": "2018-02-05T14:36:50.425000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:        0.8222222222222222\n",
      "Precision:       [0.78571429 0.88235294]\n",
      "Recall:          [0.91666667 0.71428571]\n",
      "F1-Score:        [0.84615385 0.78947368]\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy:       \",accuracy_score(y_test, y_pred2))\n",
    "print (\"Precision:      \",precision_score(y_test, y_pred2,average=None))\n",
    "print (\"Recall:         \",recall_score(y_test, y_pred2,average=None))\n",
    "print (\"F1-Score:       \",f1_score(y_test, y_pred2,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        48\n",
      "           1       0.88      0.71      0.79        42\n",
      "\n",
      "    accuracy                           0.82        90\n",
      "   macro avg       0.83      0.82      0.82        90\n",
      "weighted avg       0.83      0.82      0.82        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:36:54.751000Z",
     "start_time": "2018-02-05T14:36:54.689000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.86666667 0.83333333 0.76666667 0.96666667 0.8        0.76666667\n",
      " 0.8        0.86206897 0.75862069 0.86206897]\n",
      "CV accuracy: 0.828 +/- 0.061\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=pipe2,X=X, y=y,cv=10,n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From the comparison of the metrics of the two experiments - with and without One-Hot-Encoding - we conclude:\n",
    "\n",
    "1. The pipe without One-Hot-Encoding yields a better accuracy\n",
    "2. Also the most important metric for an application like this, the recall of class disease, is much better without One-Hot-Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain model by analysing feature importance\n",
    "Understanding the learned model and it's decision process is crucial for many ML-applications. Methods that provide an understanding of the model are summarised under the term **explainability.**\n",
    "\n",
    "Binary Linear classifiers learn the parameters $c_i$ of a linear function\n",
    "\n",
    "$$\n",
    "c(\\mathbf{x})=c_0 + c_1 x_1 + c_2 x_2 + \\ldots + c_d x_d, \n",
    "$$\n",
    "\n",
    "where $x_i$ refers to the $i.th$ input-feature.\n",
    "\n",
    "The learned coefficients $c_i$ indicate the influence of the $i.th$ input-feature on the classification-decision and therefore provide explainability. More concrete:\n",
    "\n",
    "* the sign of the $i.th$ coefficient determines if the $i.th$ input-feature has a positive or a negative influence on predicting the class, which belongs to the higher index. I.e. if the sign of the $c_i$ is positive, then an increasing value of $x_i$ yields a stronger trend towards the class with index $1$. Correspondingly, if the sign of the $c_i$ is negative, then an increasing value of $x_i$ yields a stronger trend towards the class with index $0$.\n",
    "* the magnitude of the $i.th$ coefficient, determines how strong the $i.th$ input-feature influences the decision. If the value of $c_i$ is close to 0, then the $i.th$ feature $x_i$ has almost no influence on the classifier's decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned classifier within the pipe can be accessed by `pipe2.steps[1][1]`. Since this model is an object of class [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), it's learned coefficients $c_i$ can be accessed by the `coef_`-attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:37:20.801000Z",
     "start_time": "2018-02-05T14:37:20.801000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11726704  0.34678085  0.45483522  0.4162915   0.13773092 -0.13983385\n",
      "   0.10235511 -0.3609869   0.45228867  0.32454779  0.21666456  0.5236764\n",
      "   0.53528568]]\n",
      "(1, 13)\n"
     ]
    }
   ],
   "source": [
    "feature_importance= pipe2.steps[1][1].coef_\n",
    "print(feature_importance)\n",
    "print(feature_importance.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These coefficients are visualized in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:37:22.119000Z",
     "start_time": "2018-02-05T14:37:21.791000+01:00"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Users/johannes/gitprojects/dsmmlbook/mlbook/_build/jupyter_execute/Lecture/03ClassificationPipe_71_0.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_feats=len(feature_importance[0])\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.bar(range(n_feats),feature_importance[0],)\n",
    "plt.xticks(np.arange(n_feats)+0.4,featureNames,rotation=90,fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.title(\"Importance of Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot we can infer for example: \n",
    "* the parameter `thal` (heartrate) has the strongest influence on class `disease`. As defined above `thal=3` indicates a normal heartrate and `thal=6` and `thal=7` refer to pathological heartrates. Since the sign of `thal` is positive: The higher the value, the more likely is class `disease`.\n",
    "* the parameter `thalach` (maximum achieved heartrate) has the strongest negative impact on `disease`. The higher the maximum achieved heartrate the less likely is class `disease`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Model\n",
    "In the previous section we considered the disease-detection problem as a binary-classification task. We have not been interesting in the level of disease, we just wanted to know if the input-features indicate any disease or not. \n",
    "\n",
    "However, in the dataset 4 different levels of disease are distinguished. We know won't treat all diseases as one but like to distinguish the different levels. Since we have 4 different diseases and the non-disease case, we now have to implement multiclass-classifier for 5 different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 50 class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:38:20.549000Z",
     "start_time": "2018-02-05T14:38:20.534000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 0 0 0 3 0 2 1 0 0 2 0 0 0 1 0 0 0 0 0 1 3 4 0 0 0 0 3 0 2 1 0 0 0 3\n",
      " 1 3 0 4 0 0 0 1 4 0 4 0 0]\n"
     ]
    }
   ],
   "source": [
    "y=indf[\"num\"].values\n",
    "print(y[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of class labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:38:22.018000Z",
     "start_time": "2018-02-05T14:38:21.831000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([160.,  54.,  35.,  35.,  13.]), array([0, 1, 2, 3, 4, 5]), <a list of 5 Patch objects>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Users/johannes/gitprojects/dsmmlbook/mlbook/_build/jupyter_execute/Lecture/03ClassificationPipe_77_1.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelhist=plt.hist(y,bins=[0,1,2,3,4,5])\n",
    "plt.xticks(np.arange(5)+0.5,np.arange(5))\n",
    "plt.title(\"Distribution of class-labels over \")\n",
    "print(labelhist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class-distribution, visualized above indicates a severe problem in Machine Learning: We have a relatively low number of labeled data and the number of samples per class strongly varies. This so called **inbalanced data problem** may yield a model, which is strongly *biased* towards the class(es), with much samples (class 0 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:38:25.721000Z",
     "start_time": "2018-02-05T14:38:25.706000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:38:31.754000Z",
     "start_time": "2018-02-05T14:38:31.738000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "pipe3 = Pipeline([('stdSc', StandardScaler(with_mean=True)),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)),\n",
    "                 #('clf', LogisticRegression(C=0.1,class_weight=\"balanced\",random_state=1)), \n",
    "                ])\n",
    "pipe3.fit(X_train,y_train)\n",
    "y_pred3=pipe3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:38:35.136000Z",
     "start_time": "2018-02-05T14:38:34.907000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  3  1  0  0]\n",
      " [12  1  1  3  0]\n",
      " [ 1  2  2  5  0]\n",
      " [ 2  1  5  1  1]\n",
      " [ 2  1  2  0  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 180x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Users/johannes/gitprojects/dsmmlbook/mlbook/_build/jupyter_execute/Lecture/03ClassificationPipe_81_1.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mat3 = confusion_matrix(y_test, y_pred3)\n",
    "print(confusion_mat3)\n",
    "plot_confusion_matrix(confusion_mat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:38:49.292000Z",
     "start_time": "2018-02-05T14:38:49.276000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:        0.5333333333333333\n",
      "Precision:       [0.72131148 0.125      0.18181818 0.11111111 0.        ]\n",
      "Recall:          [0.91666667 0.05882353 0.2        0.1        0.        ]\n",
      "F1-Score:        [0.80733945 0.08       0.19047619 0.10526316 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:       \",accuracy_score(y_test, y_pred3))\n",
    "print(\"Precision:      \",precision_score(y_test, y_pred3,average=None))\n",
    "print(\"Recall:         \",recall_score(y_test, y_pred3,average=None))\n",
    "print(\"F1-Score:       \",f1_score(y_test, y_pred3,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:39:43.661000Z",
     "start_time": "2018-02-05T14:39:43.520000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.6        0.6        0.56666667 0.66666667 0.53333333 0.53333333\n",
      " 0.56666667 0.5862069  0.55172414 0.68965517]\n",
      "CV accuracy: 0.589 +/- 0.050\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=pipe3,X=X, y=y,cv=10,n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81        48\n",
      "           1       0.12      0.06      0.08        17\n",
      "           2       0.18      0.20      0.19        10\n",
      "           3       0.11      0.10      0.11        10\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.53        90\n",
      "   macro avg       0.23      0.26      0.24        90\n",
      "weighted avg       0.44      0.53      0.48        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix and the classification-metrics show, that we actually ran into the **inbalanced class problem**. Due to the over-presence of class-0-data, most of the test-data is classified to be class 0. Hence the recall in the other classes is quite small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient and fast comparison of different processing pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning is an empirical science. In order to find a good model for the given task and data one must implement many processing pipelines with different algorithms, hyper-parameters and pre-processing-routines. Each of these configurations must be learned and validated. \n",
    "\n",
    "The scikit-learn `Pipeline`-class supports the configuration, training and validation of multiple processing-pipelines and there efficient comparison. This is demonstrated in this subsection. \n",
    "\n",
    "For simplicity reasons, in this subsection we again consider the binary-classification problem. I.e\n",
    "\n",
    "* class-label 0 is clipped to 0\n",
    "* class-labels 1,2,3,4 are clipped to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:39:54.425000Z",
     "start_time": "2018-02-05T14:39:54.425000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First class labels:   [0 1 1 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "BINCLASS=True\n",
    "y=indf[\"num\"].values\n",
    "if BINCLASS:\n",
    "    y=np.clip(y,a_min=0,a_max=1)\n",
    "print(\"First class labels:  \",y[:8])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define multiple pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:39:59.863000Z",
     "start_time": "2018-02-05T14:39:59.628000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "catFeats=[2,6,12]\n",
    "pipe1 = Pipeline([\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])\n",
    "\n",
    "pipe2 = Pipeline([('oneHot', compose.make_column_transformer((OneHotEncoder(categories=\"auto\"), catFeats), remainder=\"passthrough\"\n",
    ")),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])\n",
    "\n",
    "pipe3 = Pipeline([('stdSc', StandardScaler(with_mean=True)),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])\n",
    "pipe4 = Pipeline([('oneHot', compose.make_column_transformer((OneHotEncoder(categories=\"auto\"), catFeats), remainder=\"passthrough\"\n",
    ")),\n",
    "                 ('stdSc', StandardScaler(with_mean=True)),\n",
    "                 #('pca', PCA(n_components=2)),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])\n",
    "pipe5 = Pipeline([('oneHot', compose.make_column_transformer((OneHotEncoder(categories=\"auto\"), catFeats), remainder=\"passthrough\"\n",
    ")),\n",
    "                 ('stdSc', StandardScaler(with_mean=False)),\n",
    "                 #('pca', PCA(n_components=2)),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])\n",
    "pipe6 = Pipeline([('oneHot', compose.make_column_transformer((OneHotEncoder(categories=\"auto\"), catFeats), remainder=\"passthrough\"\n",
    ")),\n",
    "                 ('stdSc', MinMaxScaler()),\n",
    "                 #('pca', PCA(n_components=2)),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])\n",
    "pipe7 = Pipeline([('oneHot', compose.make_column_transformer((OneHotEncoder(categories=\"auto\"), catFeats), remainder=\"passthrough\"\n",
    ")),\n",
    "                 ('stdSc', StandardScaler(with_mean=True)),\n",
    "                 ('featsel',SelectKBest(f_classif,k=8)), \n",
    "                 #('pca', PCA(n_components=2)),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])\n",
    "pipe8 = Pipeline([('oneHot', compose.make_column_transformer((OneHotEncoder(categories=\"auto\"), catFeats), remainder=\"passthrough\"\n",
    ")),\n",
    "                 ('stdSc', StandardScaler(with_mean=True)), \n",
    "                 ('pca', PCA(n_components=2)),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])\n",
    "pipe9 = Pipeline([('oneHot', compose.make_column_transformer((OneHotEncoder(categories=\"auto\"), catFeats), remainder=\"passthrough\"\n",
    ")),\n",
    "                 ('stdSc', StandardScaler(with_mean=True)), \n",
    "                 ('lda', LinearDiscriminantAnalysis(n_components=1)),\n",
    "                 ('clf', LogisticRegression(C=0.1,random_state=1)) \n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we apply cross-validation for each of the pipelines defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:39:59.863000Z",
     "start_time": "2018-02-05T14:39:59.628000+01:00"
    }
   },
   "outputs": [],
   "source": [
    "scores = [\n",
    "    cross_val_score(mypipe, X, y, scoring='accuracy')\n",
    "            for mypipe in [pipe1,pipe2,pipe3,pipe4,pipe5,pipe6,pipe7,pipe8,pipe9]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below just cares for a more informative output of the accuracy-values of each pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-05T13:40:11.748000Z",
     "start_time": "2018-02-05T14:40:11.748000+01:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.15% (+/- 2.50%), only logistic Regression\n",
      "Accuracy: 84.84% (+/- 3.41%), LogReg+OneHotEncoding\n",
      "Accuracy: 82.81% (+/- 3.01%), LogReg+Scaling with mean\n",
      "Accuracy: 82.82% (+/- 4.48%), LogReg+OneHot+StdScaling with mean\n",
      "Accuracy: 82.82% (+/- 4.48%), LogReg+OneHot+StdScaling without mean\n",
      "Accuracy: 82.47% (+/- 3.01%), LogReg+OneHot+MinmaxScaling\n",
      "Accuracy: 84.14% (+/- 4.69%), LogReg+OneHot+StdScaling with mean + select k best\n",
      "Accuracy: 84.17% (+/- 3.46%), LogReg+OneHot+StdScaling with mean + PCA\n",
      "Accuracy: 83.15% (+/- 4.91%), LogReg+OneHot+StdScaling with mean + LDA\n"
     ]
    }
   ],
   "source": [
    "for score,label in zip(scores, \n",
    "                       ['only logistic Regression', \n",
    "                        'LogReg+OneHotEncoding',\n",
    "                        'LogReg+Scaling with mean', \n",
    "                        'LogReg+OneHot+StdScaling with mean',\n",
    "                        'LogReg+OneHot+StdScaling without mean',\n",
    "                        'LogReg+OneHot+MinmaxScaling',\n",
    "                        'LogReg+OneHot+StdScaling with mean + select k best',\n",
    "                        'LogReg+OneHot+StdScaling with mean + PCA',\n",
    "                        'LogReg+OneHot+StdScaling with mean + LDA',\n",
    "                        ]\n",
    "                       ):\n",
    "    print(\"Accuracy: {:.2%} (+/- {:.2%}), {:}\".format(score.mean(), score.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the implemented processing chains, the one with one-hot-encoding and logistic regression performs best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterized Pipelines\n",
    "As shown in the next cell, pipeline-objects can also be parameterized. Here, Multi-Layer-Perceptrons with different numbers of hidden layers and different numbers of neurons per hidden-layer are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelist=[]\n",
    "hiddenConfs=[(10,),(30,),(50,),(100,),(10,10),(30,30),(50,50),(100,50),(100,100),(200,100),(200,200)]\n",
    "for idx,hid in enumerate(hiddenConfs):\n",
    "    pipe=Pipeline([\n",
    "                    (\"mlp_\"+str(idx),MLPClassifier(hidden_layer_sizes=hid,max_iter=1000))\n",
    "                  ])\n",
    "    pipelist.append(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [ cross_val_score(reg,X,y,scoring='accuracy') for reg in pipelist ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.70 (+/-  0.16) \t for network (10,) \n",
      "Accuracy:  0.80 (+/-  0.03) \t for network (30,) \n",
      "Accuracy:  0.81 (+/-  0.04) \t for network (50,) \n",
      "Accuracy:  0.76 (+/-  0.07) \t for network (100,) \n",
      "Accuracy:  0.82 (+/-  0.04) \t for network (10, 10) \n",
      "Accuracy:  0.77 (+/-  0.02) \t for network (30, 30) \n",
      "Accuracy:  0.77 (+/-  0.03) \t for network (50, 50) \n",
      "Accuracy:  0.80 (+/-  0.02) \t for network (100, 50) \n",
      "Accuracy:  0.74 (+/-  0.05) \t for network (100, 100) \n",
      "Accuracy:  0.75 (+/-  0.04) \t for network (200, 100) \n",
      "Accuracy:  0.75 (+/-  0.03) \t for network (200, 200) \n"
     ]
    }
   ],
   "source": [
    "for score,label in zip(scores,hiddenConfs):\n",
    "    print(\"Accuracy: %5.2f (+/- %5.2f) \\t for network %s \"%(score.mean(), score.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the pipelines above, integrates scaling. However, scaling of input-features is crucial for neural networks. The next pipeline-list contains the same pipelines as above, but now with *MinMax-Scaling*.\n",
    "As can be seen, the accuracy-values are much better now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelist=[]\n",
    "hiddenConfs=[(10,),(30,),(50,),(100,),(10,10),(30,30),(50,50),(100,50),(100,100),(200,100),(200,200)]\n",
    "for idx,hid in enumerate(hiddenConfs):\n",
    "    pipe=Pipeline([('stdSc', MinMaxScaler()),\n",
    "                    (\"mlp_\"+str(idx),MLPClassifier(hidden_layer_sizes=hid,max_iter=1000))\n",
    "                  ])\n",
    "    pipelist.append(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [ cross_val_score(reg,X,y,scoring='accuracy') for reg in pipelist ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.84 (+/-  0.04) \t for network (10,) \n",
      "Accuracy:  0.83 (+/-  0.04) \t for network (30,) \n",
      "Accuracy:  0.80 (+/-  0.04) \t for network (50,) \n",
      "Accuracy:  0.80 (+/-  0.03) \t for network (100,) \n",
      "Accuracy:  0.80 (+/-  0.03) \t for network (10, 10) \n",
      "Accuracy:  0.81 (+/-  0.05) \t for network (30, 30) \n",
      "Accuracy:  0.77 (+/-  0.05) \t for network (50, 50) \n",
      "Accuracy:  0.79 (+/-  0.02) \t for network (100, 50) \n",
      "Accuracy:  0.79 (+/-  0.04) \t for network (100, 100) \n",
      "Accuracy:  0.80 (+/-  0.04) \t for network (200, 100) \n",
      "Accuracy:  0.77 (+/-  0.05) \t for network (200, 200) \n"
     ]
    }
   ],
   "source": [
    "for score,label in zip(scores,hiddenConfs):\n",
    "    print(\"Accuracy: %5.2f (+/- %5.2f) \\t for network %s \"%(score.mean(), score.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "toc_position": {
   "height": "643px",
   "left": "0px",
   "right": "1484px",
   "top": "125.233px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}